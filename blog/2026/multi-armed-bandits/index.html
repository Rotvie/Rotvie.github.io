<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Multi-Armed Bandit Problem | Ricardo Huaman </title> <meta name="author" content="Ricardo J. Huaman K."> <meta name="description" content="A visual walkthrough of exploration vs exploitation — from YouTube thumbnails to the algorithms behind smart experimentation"> <meta name="keywords" content="robotics, ai, computer science, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://rotvie.github.io/blog/2026/multi-armed-bandits/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "The Multi-Armed Bandit Problem",
            "description": "A visual walkthrough of exploration vs exploitation — from YouTube thumbnails to the algorithms behind smart experimentation",
            "published": "February 23, 2026",
            "authors": [
              
              {
                "author": "Ricardo Huaman",
                "authorURL": "https://rotvie.github.io/",
                "affiliations": [
                  {
                    "name": "Independent",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Ricardo Huaman </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>The Multi-Armed Bandit Problem</h1> <p>A visual walkthrough of exploration vs exploitation — from YouTube thumbnails to the algorithms behind smart experimentation</p> </d-title> <d-byline></d-byline> <d-article> <h2 id="the-multi-armed-bandit-problem">The Multi-Armed Bandit Problem</h2> <p>There are many resources that explain multi-armed bandits as “a smarter A/B test.” While that’s one application, it undersells what’s going on. The bandit problem captures something more fundamental: <strong>how do you make good decisions when every choice teaches you something about the world?</strong> <d-cite key="Slivkins_2019"></d-cite></p> <p>This post builds the full picture — starting from a problem every content creator faces, formalizing it into math, and then walking through three algorithms that solve it in fundamentally different ways.</p> <h2 id="you-just-uploaded-a-video">You Just Uploaded a Video</h2> <p>You’ve spent a week editing a video and it’s ready to publish. But which thumbnail should you use? You’ve prepared <strong>5 candidates</strong> — different compositions, text overlays, color palettes. Each thumbnail will attract a different fraction of viewers who see it in their feed. You want to find the best one as quickly as possible.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mab-five-thumbnails-480.webp 480w,/assets/img/mab-five-thumbnails-800.webp 800w,/assets/img/mab-five-thumbnails-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/mab-five-thumbnails.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Five thumbnail candidates" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Five thumbnail candidates for the same video. Each has an unknown click-through rate (CTR) — the fraction of viewers who click when they see it in their feed. </div> <p>YouTube actually does something like this internally. When you upload a video, it can show different thumbnails to different viewers and track which one gets the most clicks. But how should it allocate impressions across the candidates?</p> <h3 id="the-naive-approach-equal-split">The naive approach: equal split</h3> <p>The standard approach is a fixed A/B test: split impressions equally across all 5 thumbnails for a few days, then keep the winner. Simple, statistically valid — but during that test period, you’re sending <strong>equal impressions to every thumbnail, including the bad ones</strong>.</p> <p>Say T3 has an 8% CTR and T1 has a 2% CTR. An equal-split test keeps showing T1 to 20% of your audience for the entire test. Every impression spent on T1 instead of T3 is a potential click lost.</p> <h3 id="the-smarter-approach-adapt-as-you-learn">The smarter approach: adapt as you learn</h3> <p>A bandit algorithm starts by exploring all thumbnails, but as it gathers evidence, it <strong>shifts impressions toward the winners</strong> while still occasionally checking the others. Fewer wasted impressions, faster convergence to the best thumbnail.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mab-ab-vs-bandit-allocation-480.webp 480w,/assets/img/mab-ab-vs-bandit-allocation-800.webp 800w,/assets/img/mab-ab-vs-bandit-allocation-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/mab-ab-vs-bandit-allocation.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="A/B test vs bandit allocation" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> An A/B test splits impressions equally (left). A bandit algorithm shifts traffic toward the best-performing thumbnail as evidence accumulates (right). </div> <p>This is the multi-armed bandit problem: balancing <strong>exploiting</strong> what’s working with <strong>exploring</strong> what might work better.</p> <h2 id="formal-definition">Formal Definition</h2> <p>Let’s translate this into math.</p> <p>You have $K$ thumbnail candidates. Each thumbnail $i$ has a true CTR $\theta_i$ that you don’t know. Every time an impression is served (time step $t$), you choose which thumbnail to show (action $a_t$). The viewer either clicks ($r_t = 1$) or scrolls past ($r_t = 0$):</p> \[P(r_t = 1) = \theta_{a_t}\] <p>This is called a <strong>Bernoulli bandit</strong> — each action gives a binary outcome, like a coin flip with unknown bias <d-cite key="Lattimore_Szepesvari_2020"></d-cite>.</p> <h3 id="why-multi-armed-bandit">Why “Multi-Armed Bandit”?</h3> <p>The name comes from slot machines. A “one-armed bandit” is a single slot machine — one lever, steals your money. A “multi-armed bandit” is the problem of facing $K$ machines at once, each with a different hidden payout. Pull an arm, observe the reward, decide which arm to pull next. Your 5 thumbnails are your 5 arms.</p> <h3 id="regret">Regret</h3> <p>We measure performance by <strong>regret</strong> — the total clicks lost by not always showing the best thumbnail:</p> \[\mathcal{L}_T = \sum_{t=1}^{T} (\theta^* - \theta_{a_t}), \quad \theta^* = \max_i \theta_i\] <p>Every impression spent on a suboptimal thumbnail adds some regret. A good algorithm minimizes this.</p> <h3 id="the-estimation-problem">The Estimation Problem</h3> <p>You estimate each thumbnail’s CTR from observed data:</p> \[\hat{Q}_t(a) = \frac{\text{clicks on thumbnail } a}{\text{impressions of thumbnail } a }\] <p>The catch: <strong>early estimates are noisy</strong>. After showing T3 to just 50 viewers, your estimated CTR could be anywhere from 0% to 16%, even if the true CTR is 8%. This noise is what makes the problem hard — and it’s why the three algorithms below take fundamentally different approaches to dealing with it.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mab-estimation-noise-480.webp 480w,/assets/img/mab-estimation-noise-800.webp 800w,/assets/img/mab-estimation-noise-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/mab-estimation-noise.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Noisy estimates" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> After 50 impressions per thumbnail, error bars are wide and overlap — you can't confidently pick the winner. After 2,000 each, estimates are tight — but that's 10,000 impressions, most wasted on bad thumbnails. </div> <h2 id="algorithm-1-varepsilon-greedy">Algorithm 1: $\varepsilon$-Greedy</h2> <p>The simplest bandit strategy. Most of the time, show the thumbnail with the highest estimated CTR. Occasionally, try a random one:</p> \[a_t = \begin{cases} \displaystyle\operatorname*{argmax}_a \hat{Q}_t(a) &amp; \text{with probability } 1 - \varepsilon \quad (\text{show the current best}) \\ \text{random thumbnail} &amp; \text{with probability } \varepsilon \quad (\text{try something random}) \end{cases}\] <p>Set $\varepsilon = 0.1$ and 10% of impressions go to a random thumbnail.</p> <p><strong>Why it works (sort of):</strong> the random explorations help you discover if a different thumbnail is actually better. Over time, estimates converge and you mostly exploit the true winner.</p> <p><strong>Why it’s limited:</strong> that random 10% is <em>blind</em>. It doesn’t care whether you’ve already confirmed a thumbnail is terrible. After 10,000 impressions, you might have rock-solid evidence that T1 has a 2% CTR, and $\varepsilon$-Greedy will still randomly show it. Those are wasted impressions — viewers who could have been shown T3.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mab-epsilon-greedy-results-480.webp 480w,/assets/img/mab-epsilon-greedy-results-800.webp 800w,/assets/img/mab-epsilon-greedy-results-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/mab-epsilon-greedy-results.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Epsilon-greedy results" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> $\varepsilon$-Greedy with different exploration rates. Too little exploration ($\varepsilon = 0$) risks getting stuck on a suboptimal thumbnail. Too much ($\varepsilon = 0.3$) wastes impressions on thumbnails already known to be bad. The regret keeps growing linearly — the waste never stops. </div> <h2 id="algorithm-2-upper-confidence-bounds-ucb1">Algorithm 2: Upper Confidence Bounds (UCB1)</h2> <h3 id="why-not-explore-smarter">Why Not Explore Smarter?</h3> <p>The problem with $\varepsilon$-Greedy is that it explores <em>blindly</em>. What if, instead of exploring randomly, we sent impressions specifically to <strong>thumbnails we’re still uncertain about?</strong></p> <h3 id="building-the-intuition">Building the Intuition</h3> <p>Imagine you’ve been running the test and here’s what you know:</p> <table> <thead> <tr> <th>Thumbnail</th> <th>Impressions</th> <th>Clicks</th> <th>Observed CTR</th> <th>How confident are you?</th> </tr> </thead> <tbody> <tr> <td>T1</td> <td>500</td> <td>10</td> <td>2.0%</td> <td>Very confident — it’s bad</td> </tr> <tr> <td>T2</td> <td>500</td> <td>26</td> <td>5.2%</td> <td>Pretty confident</td> </tr> <tr> <td>T3</td> <td>12</td> <td>1</td> <td>8.3%</td> <td><strong>Not confident at all!</strong></td> </tr> <tr> <td>T4</td> <td>500</td> <td>14</td> <td>2.8%</td> <td>Very confident — it’s bad</td> </tr> <tr> <td>T5</td> <td>500</td> <td>21</td> <td>4.2%</td> <td>Pretty confident</td> </tr> </tbody> </table> <p>T3 <em>looks</em> great at 8.3%, but you’ve only shown it 12 times. That could easily be noise — maybe nobody happened to be in the mood to click. Or maybe it really is the best. <strong>You should show it more to find out.</strong></p> <p>Meanwhile, T1 and T4 have been shown 500 times each. You’re very confident they’re bad. There’s no point sending more impressions their way.</p> <p>UCB1 formalizes exactly this intuition. For each thumbnail, it computes a score that combines two things:</p> \[\text{UCB score}(a) = \underbrace{\hat{Q}_t(a)}_{\text{estimated CTR}} + \underbrace{\sqrt{\frac{2 \ln t}{N_t(a)}}}_{\text{how uncertain you are}}\] <p>Then it shows the thumbnail with the highest score.</p> <p>The second term captures your uncertainty about the estimate. It’s large when $N_t(a)$ is small (few impressions → uncertain → explore), and shrinks as you gather data (many impressions → confident → trust the estimate).</p> <h3 id="where-does-the-uncertainty-term-come-from">Where Does the Uncertainty Term Come From?</h3> <p>It comes from <strong>Hoeffding’s Inequality</strong>, a result from probability theory that bounds how far a sample mean can deviate from the true mean <d-cite key="Auer_2002"></d-cite>.</p> <p>Hoeffding tells you: given $N$ observations of a random variable bounded in $[0,1]$, the probability that the true mean exceeds the sample mean by more than $u$ is at most $e^{-2Nu^2}$.</p> <p>If we want to be very sure (probability $\leq t^{-4}$, which is vanishingly small) that our upper bound covers the true CTR, we set $e^{-2Nu^2} = t^{-4}$ and solve:</p> \[e^{-2Nu^2} = t^{-4} \implies u = \sqrt{\frac{2\ln t}{N}}\] <p>That’s the uncertainty term. It’s a statistically rigorous confidence bound — hence the name “Upper Confidence Bound.”</p> <p>The philosophy is sometimes called <strong>“optimism in the face of uncertainty”</strong>: act as if each thumbnail is as good as it <em>plausibly could be</em> given the data. Under-explored thumbnails get the benefit of the doubt.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mab-ucb-scores-480.webp 480w,/assets/img/mab-ucb-scores-800.webp 800w,/assets/img/mab-ucb-scores-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/mab-ucb-scores.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="UCB score decomposition" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> UCB1 scores for each thumbnail. The uncertainty term (lighter bar) is large for T3 (only 12 impressions) and tiny for well-explored thumbnails. UCB1 sends the next impression to T3 — the thumbnail it knows the least about. </div> <h2 id="algorithm-3-thompson-sampling">Algorithm 3: Thompson Sampling</h2> <h3 id="a-different-way-to-handle-uncertainty">A Different Way to Handle Uncertainty</h3> <p>UCB1 uses a formula to put a number on uncertainty. Thompson Sampling takes a different route: it maintains a <strong>full probability distribution</strong> representing your belief about each thumbnail’s true CTR, and uses randomness to decide what to explore <d-cite key="Chapelle_Li_2011"></d-cite>.</p> <h3 id="beliefs-as-beta-distributions">Beliefs as Beta Distributions</h3> <p>For each thumbnail, you keep a belief: <em>“given everything I’ve observed, what could this thumbnail’s true CTR be?”</em> This belief is a <strong>Beta distribution</strong> $\text{Beta}(\alpha, \beta)$, where:</p> <ul> <li>$\alpha$ = clicks + 1</li> <li>$\beta$ = non-clicks + 1</li> </ul> <p>If T2 has received 100 impressions, 5 clicks, 95 skips: the belief is $\text{Beta}(6, 96)$ — peaked near 5%, fairly narrow. You’re reasonably confident.</p> <p>If T3 has received 3 impressions, 1 click: the belief is $\text{Beta}(2, 3)$ — a very wide distribution spanning nearly the whole range from 0% to 70%. You have almost no idea what T3’s true CTR is.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mab-beta-distributions-480.webp 480w,/assets/img/mab-beta-distributions-800.webp 800w,/assets/img/mab-beta-distributions-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/mab-beta-distributions.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Beta distributions at different stages" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The Beta distribution sharpens with data. With few impressions, the belief is wide — the true CTR could be almost anything. With many impressions, the belief narrows to a tight peak near the true value. </div> <h3 id="the-algorithm">The Algorithm</h3> <p>Each time a new viewer arrives:</p> <ol> <li>For each thumbnail, <strong>draw a random value</strong> from its belief distribution.</li> <li>Show the viewer <strong>whichever thumbnail drew the highest value</strong>.</li> <li>Observe click or skip. <strong>Update the belief</strong>: click → $\alpha + 1$, skip → $\beta + 1$.</li> </ol> <p><strong>Why this works:</strong> Thumbnails you’re uncertain about have wide beliefs, so their draws occasionally land very high — they get impressions. Thumbnails you’re confident about have narrow beliefs — draws cluster near the true CTR. If it’s genuinely the best, it consistently “wins the draw.” Over time, all beliefs narrow and the best thumbnail dominates.</p> <p>This property is called <strong>probability matching</strong>: each thumbnail is selected with probability proportional to the probability that it <em>is</em> the best, given what you’ve observed <d-cite key="Russo_2017"></d-cite>.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mab-thompson-one-round-480.webp 480w,/assets/img/mab-thompson-one-round-800.webp 800w,/assets/img/mab-thompson-one-round-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/mab-thompson-one-round.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="One round of Thompson Sampling" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> One round of Thompson Sampling. Each thumbnail's belief produces a random draw. T3, with its wide belief (only 12 impressions), draws a high value and gets explored — not because of a formula, but because uncertainty naturally produces high samples. </div> <h3 id="beliefs-converge-over-time">Beliefs Converge Over Time</h3> <p>As the algorithm runs, beliefs sharpen. Early on, all distributions are wide and the algorithm explores broadly. Eventually, the best thumbnail’s distribution dominates, and almost all impressions flow there.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mab-thompson-convergence-480.webp 480w,/assets/img/mab-thompson-convergence-800.webp 800w,/assets/img/mab-thompson-convergence-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/mab-thompson-convergence.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Posterior convergence" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Thompson Sampling posteriors at four time steps. At $t = 0$, all beliefs are flat — "any CTR is equally plausible." By convergence, the best thumbnail (T3, 8% true CTR) has a sharp, dominant peak and receives nearly all impressions. </div> <h2 id="head-to-head-comparison">Head-to-Head Comparison</h2> <p>Now the main event. All three algorithms on the same 5-thumbnail problem (true CTRs: 2%, 3%, 4%, 5%, 8%), over 10,000 impressions, averaged across 30 runs.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mab-comparison-480.webp 480w,/assets/img/mab-comparison-800.webp 800w,/assets/img/mab-comparison-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/mab-comparison.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Algorithm comparison" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> (a) Cumulative regret: Thompson and UCB1 flatten, while $\varepsilon$-Greedy grows linearly. (b) Log-log plot reveals the growth rate: $O(t)$ for $\varepsilon$-Greedy, $O(\log t)$ for the others. (c) Impression distribution: Thompson concentrates nearly all impressions on the best thumbnail. </div> <p>The key result: $\varepsilon$-Greedy regret grows <strong>linearly</strong> — it never stops wasting impressions. UCB1 and Thompson Sampling grow <strong>logarithmically</strong> — the regret curve flattens as they lock onto the best thumbnail. Thompson typically achieves the lowest total regret.</p> <h2 id="beyond-thumbnails">Beyond Thumbnails</h2> <p>The explore-exploit tradeoff isn’t unique to thumbnails. It appears wherever decisions must be made under uncertainty with limited feedback:</p> <ul> <li> <strong>Ad placement</strong>: Which banner to show on a webpage. This is where bandits are most widely deployed in industry.</li> <li> <strong>Clinical trials</strong>: Choosing between a proven treatment and a promising experimental one. Bandit algorithms have been proposed for adaptive designs that shift patients toward the more effective treatment as evidence accumulates <d-cite key="Villar_2015"></d-cite>.</li> <li> <strong>Recommendation systems</strong>: Should a platform show you content it’s confident you’ll enjoy, or something new that <em>might</em> be a hit?</li> </ul> <p>Even training deep learning models involves this tradeoff. Stochastic Gradient Descent uses mini-batches that introduce noise into gradient estimates — acting as implicit exploration that helps escape local minima. It’s the same “productive randomness” that makes Thompson Sampling work.</p> <h2 id="summary">Summary</h2> <table> <thead> <tr> <th>Algorithm</th> <th>How it explores</th> <th>Regret</th> <th>Key property</th> </tr> </thead> <tbody> <tr> <td>$\varepsilon$-Greedy</td> <td>Randomly — wastes impressions on known-bad thumbnails</td> <td>Linear — $O(T)$</td> <td>Simple but inefficient</td> </tr> <tr> <td>UCB1</td> <td>Targets uncertain thumbnails via a Hoeffding-derived confidence bound</td> <td>Logarithmic — $O(\log T)$</td> <td>Deterministic, theoretically grounded</td> </tr> <tr> <td>Thompson Sampling</td> <td>Draws from belief distributions; uncertain thumbnails can “win” by chance</td> <td>Logarithmic — $O(\log T)$</td> <td>Automatic, typically lowest regret</td> </tr> </tbody> </table> <p>The core insight: <strong>information has value</strong>. Showing a viewer an under-explored thumbnail isn’t wasting that impression — it’s investing in learning which thumbnail is best, which pays off by routing all future viewers better. The question is how to make those investments wisely. $\varepsilon$-Greedy invests randomly. UCB1 and Thompson Sampling invest where it matters.</p> <h2 id="glossary">Glossary</h2> <p><strong>Click-Through Rate (CTR):</strong> The fraction of impressions that result in a click. If 1,000 viewers see a thumbnail and 50 click, the CTR is 5%.</p> <p><strong>Bernoulli Bandit:</strong> A multi-armed bandit where each arm gives a binary reward (0 or 1) with some unknown probability $\theta$.</p> <p><strong>Regret:</strong> The cumulative difference between the reward of the best arm and the arm actually chosen, summed over all time steps. Lower is better.</p> <p><strong>Upper Confidence Bound (UCB):</strong> A score combining the estimated reward with an uncertainty term derived from Hoeffding’s Inequality. Arms with fewer observations get a larger uncertainty term, encouraging exploration.</p> <p><strong>Beta Distribution:</strong> A probability distribution on the interval $[0, 1]$, parameterized by $\alpha$ and $\beta$. In Thompson Sampling, it represents the posterior belief about an arm’s true reward probability.</p> <p><strong>Probability Matching:</strong> The property that each arm is selected with probability equal to the probability it is optimal, given the observed data.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/multi-armed-bandits.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/langevin-sampling-for-diffusion/">Langevin Sampling for Diffusion Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/my-journey-learning-japanese/">My Journey Learning Japanese</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/uros/">Setting Up and Running microROS on the Raspberry Pi Pico</a> </li> <br> <br> <div id="giscus_thread"> <script defer src="/assets/js/giscus-setup.js"></script> <noscript> Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Ricardo J. Huaman K.. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: February 24, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>